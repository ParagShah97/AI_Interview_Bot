from __future__ import print_function
from __future__ import division

# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NOv5IUc4IGd3IsrJkQ_LezXE7hGkbBMb
"""


"""# New Section"""

import nltk
nltk.download('stopwords')
nltk.download('wordnet')

import nltk
from nltk.tokenize import RegexpTokenizer # Not used
from nltk.tokenize import TreebankWordTokenizer
from nltk.stem import WordNetLemmatizer,PorterStemmer
from nltk.corpus import stopwords
from nltk import metrics
import re

lemmatizer = WordNetLemmatizer()
stemmer = PorterStemmer()

def preprocess(sentence):
    sentence=str(sentence)
    sentence = sentence.lower()
    sentence=sentence.replace('{html}',"") 
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', sentence)
    rem_url=re.sub(r'http\S+', '',cleantext)
    rem_num = re.sub('[0-9]+', '', rem_url)
    #tokenizer = RegexpTokenizer(r'\w+')
    tokenizer=TreebankWordTokenizer()
    tokens = tokenizer.tokenize(rem_num)  
    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]
    stem_words=[stemmer.stem(w) for w in filtered_words]
    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]
    return " ".join(filtered_words)




def _edit_dist_init(len1, len2):
    lev = []
    for i in range(len1):
        lev.append([0] * len2)  # initialize 2D array to zero
    for i in range(len1):
        lev[i][0] = i           # column 0: 0,1,2,3,4,...
    for j in range(len2):
        lev[0][j] = j           # row 0: 0,1,2,3,4,...
    return lev

def _edit_dist_step(lev, i, j, s1, s2, transpositions=False):
    c1 = s1[i - 1]
    c2 = s2[j - 1]

    # skipping a character in s1
    a = lev[i - 1][j] + 1
    # skipping a character in s2
    b = lev[i][j - 1] + 1
    # substitution
    c = lev[i - 1][j - 1] + (c1 != c2)

    # transposition
    d = c + 1  # never picked by default
    if transpositions and i > 1 and j > 1:
        if s1[i - 2] == c2 and s2[j - 2] == c1:
            d = lev[i - 2][j - 2] + 1

    # pick the cheapest
    lev[i][j] = min(a, b, c, d)

def edit_distance(s1, s2, transpositions=False):
    """
    Calculate the Levenshtein edit-distance between two strings.
    The edit distance is the number of characters that need to be
    substituted, inserted, or deleted, to transform s1 into s2.  For
    example, transforming "rain" to "shine" requires three steps,
    consisting of two substitutions and one insertion:
    "rain" -> "sain" -> "shin" -> "shine".  These operations could have
    been done in other orders, but at least three steps are needed.

    This also optionally allows transposition edits (e.g., "ab" -> "ba"),
    though this is disabled by default.

    :param s1, s2: The strings to be analysed
    :param transpositions: Whether to allow transposition edits
    :type s1: str
    :type s2: str
    :type transpositions: bool
    :rtype int
    """
    # set up a 2-D array
    len1 = len(s1)
    len2 = len(s2)
    lev = _edit_dist_init(len1 + 1, len2 + 1)

    # iterate over the array
    for i in range(len1):
        for j in range(len2):
            _edit_dist_step(lev, i + 1, j + 1, s1, s2, transpositions=transpositions)
    return lev[len1][len2]

def fuzzy_match(s1, s2, max_dist=3):
    #return edit_distance(s1,s2) <= max_dist
    return edit_distance(s1,s2,transpositions=False)

#s='constructor name should be the same as the class name It cannot contain any return type It can have all Access Modifiers are allowed (private , public, protected, default) It Cannot have any Non Access Modifiers (final ,static, abstract, synchronized) No return statement is allowed It can take any number of parameters Constructor can throw exception, we can have throws clause'
#s1='Constructor is just like a special method in Java that is used to initialize the state of an object and will be invoked during the time of object creation.'
#s2='Constructor is a special method provided in Java language for creating and initializing an object. In java, the role of a constructor is only to initialize an object and new key role is creating an object.'
s1='The Object is the real-time entity having some state and behavior. In Java, Object is an instance of the class having the instance variables as the state of the object and the methods as the behavior of the object. The object of a class can be created by using the new keyword'
s2='Object in java is instance of class, it is an entity having copy of all the local variable , object is created using new keyword'

t1=str(preprocess(s1))
t2=str(preprocess(s2))
#print("Actual : ",s)

t1=t1.replace(".","")
t2=t2.replace(".","")
print("t1 is : ",t1)
print("t2 is : ",t2)
#print("Final ",t1)
r=fuzzy_match(t1,t2)
print("R value is : ",r)

#pip install fuzzywuzzy

#pip install python-Levenshtein

from fuzzywuzzy import fuzz 
from fuzzywuzzy import process

print ("FuzzyWuzzy Ratio: ", fuzz.ratio(s1, s2))
print ("FuzzyWuzzy PartialRatio: ", fuzz.partial_ratio(s1, s2))
print ("FuzzyWuzzy TokenSortRatio: ", fuzz.token_sort_ratio(s1, s2)) 
print ("FuzzyWuzzy TokenSetRatio: ", fuzz.token_set_ratio(s1, s2)) 
print ("FuzzyWuzzy WRatio: ", fuzz.WRatio(s1, s2),'\n\n')

print ("FuzzyWuzzy Ratio: ", fuzz.ratio(t1, t2))
print ("FuzzyWuzzy PartialRatio: ", fuzz.partial_ratio(t1, t2))
print ("FuzzyWuzzy TokenSortRatio: ", fuzz.token_sort_ratio(t1, t2)) 
print ("FuzzyWuzzy TokenSetRatio: ", fuzz.token_set_ratio(t1, t2)) 
print ("FuzzyWuzzy WRatio: ", fuzz.WRatio(t1, t2),'\n\n')

from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd
documents=[s1,s2]
count_vectorizer = CountVectorizer(stop_words='english')
#count_vectorizer = CountVectorizer()
sparse_matrix = count_vectorizer.fit_transform(documents)
print(sparse_matrix)

doc_term_matrix = sparse_matrix.todense()
df = pd.DataFrame(doc_term_matrix, 
                  columns=count_vectorizer.get_feature_names(), 
                  index=['s1','s2'])
df

from sklearn.metrics.pairwise import cosine_similarity
print(cosine_similarity(df, df))